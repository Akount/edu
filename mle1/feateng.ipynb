{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "feateng.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "GAL-UUWK2rSL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h1> Feature Engineering </h1>\n",
        "\n",
        "In this notebook, you will learn how to incorporate feature engineering into your pipeline. This includes:\n",
        "<ul>\n",
        "<li> Working with feature columns </li>\n",
        "<li> Adding feature crosses in TensorFlow </li>\n",
        "<li> Reading data from BigQuery </li>\n",
        "<li> Creating datasets using Dataflow </li>\n",
        "<li> Using a wide-and-deep model </li>\n",
        "</ul>\n",
        "\n",
        "---\n",
        "Before you start, **make sure that you are logged in with your student account**. Otherwise you may incur Google Cloud charges for using this notebook. \n",
        "\n",
        "---"
      ]
    },
    {
      "metadata": {
        "id": "U8ihmFF42w9H",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@markdown Copy-paste your GCP Project ID in the following field:\n",
        "\n",
        "PROJECT = \"\" #@param {type: \"string\"}\n",
        "\n",
        "\n",
        "#@markdown When running this cell you will need to **uncheck \"Reset all runtimes before running\"** as shown on the following screenshot:\n",
        "#@markdown ![](https://i.imgur.com/9dgw0h0.png)\n",
        "#@markdown Next, use Shift-Enter to run this cell and to complete authentication.\n",
        "\n",
        "try:  \n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()  \n",
        "  print(\"AUTHENTICATED\")\n",
        "except:\n",
        "  print(\"FAILED to authenticate\")\n",
        "  \n",
        "REGION = \"us-central1\"   \n",
        "BUCKET = PROJECT\n",
        "\n",
        "# Copy taxi-*.csv files from github if they are missing from the runtime.\n",
        "!wget -nc --quiet https://github.com/osipov/training-data-analyst/raw/master/bootcamps/serverless_ml/taxi-11k-datasets.zip  \n",
        "!unzip -q -n taxi-11k-datasets.zip  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u2hh1tIB2rSU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h2> Environment variables for project and bucket </h2>\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "mAkP-6w32rSY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# for bash\n",
        "import os\n",
        "os.environ['PROJECT'] = PROJECT\n",
        "os.environ['BUCKET'] = BUCKET\n",
        "os.environ['REGION'] = REGION\n",
        "os.environ['TF_VERSION'] = '1.12' "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vk4PlufJ2rSa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "gcloud config set project $PROJECT\n",
        "gcloud config set compute/region $REGION"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U9KQwva4uHh-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "rm -rf taxifare\n",
        "mkdir -p taxifare/trainer\n",
        "\n",
        "for file in taxifare/setup.py \\\n",
        "            taxifare/trainer/__init__.py \\\n",
        "            taxifare/trainer/model.py \\\n",
        "            taxifare/trainer/task.py\n",
        "do\n",
        "  wget --quiet -nc \\\n",
        "  https://github.com/osipov/edu/raw/master/mle1/feateng/$file \\\n",
        "  -O $file\n",
        "done\n",
        "\n",
        "find taxifare"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gV_JWkeT2rTK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "After running the next cell, notice the new placeholders for features in the INPUT_COLUMNS. The two new categorical features are for the day of the week (`dayofweek`) and the hour of the day (`hourofday`). Also, there are three engineered feature placeholders: two for representing differences between latitude and longitude coordinates (`latdiff` and `londiff`) and one with an estimated euclidean distance (`euclidean`)."
      ]
    },
    {
      "metadata": {
        "id": "d6f3VuzNrsbV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!grep -m 1 -A 16 INPUT_COLUMNS taxifare/trainer/model.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gvJE36DWQ2g1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The next cell highlights the changes in  `build estimator` to use bucketized features and feature crosses. The NumPy `np.linspace` function divides up a range into a fixed number of partitions. In this case, each of the NYC lat/lon coordinates for a taxi ride are placed into one of  `nbucket`  buckets. Finally, both location buckets and day/hour features are feature crossed to create 4 additional features."
      ]
    },
    {
      "metadata": {
        "id": "JwVyKMEZvwcb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!grep -m 1 -A 22 build_estimator taxifare/trainer/model.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MaFTw_W5dnx-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The feature definitions are grouped into wide and deep columns as shown in the next cell..."
      ]
    },
    {
      "metadata": {
        "id": "XG_yJx5RvYDA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!grep -m 1 -A 20 wide_columns taxifare/trainer/model.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_jLHTPynd57y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "...and the model is modified to use the wide-and-deep implementation called `DNNLinearCombinedRegressor`."
      ]
    },
    {
      "metadata": {
        "id": "2rL3wIxRwdBX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!grep -m 1 -A 8 DNNLinearCombinedRegressor taxifare/trainer/model.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vyuhYTyXeH72",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Notice that in the next cell, the values for the location difference and euclidean distance features are computed in-memory, as a part of the TensorFlow model implementation."
      ]
    },
    {
      "metadata": {
        "id": "jE2_9qR_wl7r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!grep -m 1 -A 14 add_engineered taxifare/trainer/model.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KSnaBLMk2rTi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h2> Hyper-parameter tune </h2>\n",
        "\n",
        "Based on my hyperparameter tuning experiments, I ended up choosing the following values:\n",
        "<ol>\n",
        "<li> train_batch_size: 512 </li>\n",
        "<li> nbuckets: 16 </li>\n",
        "<li> hidden_units: \"64 64 64 8\" </li>    \n",
        "</ol>\n",
        "\n",
        "This gives an RMSE of **$5.7**, a considerable improvement from the 8.3 we were getting earlier ... Let's try this over a larger dataset."
      ]
    },
    {
      "metadata": {
        "id": "yAm8W0812rTj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h1> Run Cloud training on 2 million row dataset </h1>\n",
        "\n",
        "This run uses as input 2 million rows and takes ~70 minutes with 10 workers (STANDARD_1 pricing tier). The model is exactly the same as above. The only changes are to the input (to use the larger dataset) and to the Cloud MLE tier (to use STANDARD_1 instead of BASIC -- STANDARD_1 is approximately 10x more powerful than BASIC). \n",
        "\n",
        "When doing distributed training, use train_steps instead of num_epochs. The distributed workers don't know how many rows there are, but we can calculate train_steps = num_rows \\* num_epochs / train_batch_size. In this case, we have 2141023 * 100 / 512 = 418168 train steps."
      ]
    },
    {
      "metadata": {
        "id": "Dvy_NDk12rTj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "OUTDIR=gs://${BUCKET}/taxifare/feateng2.2m\n",
        "JOBNAME=feateng_$(date -u +%y%m%d_%H%M%S)\n",
        "TIER=STANDARD_1 \n",
        "\n",
        "echo $OUTDIR $REGION $JOBNAME\n",
        "gsutil -m rm -rf $OUTDIR\n",
        "\n",
        "gcloud ml-engine jobs submit training $JOBNAME \\\n",
        "   --region=$REGION \\\n",
        "   --module-name=trainer.task \\\n",
        "   --package-path=${PWD}/taxifare/trainer \\\n",
        "   --job-dir=$OUTDIR \\\n",
        "   --staging-bucket=gs://$BUCKET \\\n",
        "   --scale-tier=$TIER \\\n",
        "   --runtime-version=$TF_VERSION \\\n",
        "   -- \\\n",
        "   --train_data_paths=\"gs://kmo-us-central1-misc/taxifare/2.2m/1.csv*\" \\\n",
        "   --eval_data_paths=\"gs://kmo-us-central1-misc/taxifare/2.2m/2.csv*\"  \\\n",
        "   --output_dir=$OUTDIR \\\n",
        "   --train_steps=418168 \\\n",
        "   --train_batch_size=512 --nbuckets=16 --hidden_units=\"64 64 64 8\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C5Kg_qBDXRJ6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "After you submit the job you should see a message confirming that your job was QUEUED. To monitor the progress of the job from the GCP user interface, navigate to [Jobs](https://console.cloud.google.com/mlengine/jobs) part of the Cloud ML Engine service. Use the \"View Logs\" link to get the details."
      ]
    },
    {
      "metadata": {
        "id": "E19g6ATS2rTm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Start Tensorboard"
      ]
    },
    {
      "metadata": {
        "id": "SIkq_D2jpAcX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Instead of having you wait for the model to complete training, I have already pre-trained a model on 2.2m rows of data. Use the next cell to start TensorBoard and review the average_loss and RMSE. Note that after about 1 hr 30 min of training, the model was evaluated at roughly **$4** RMSE."
      ]
    },
    {
      "metadata": {
        "id": "vOzV5fwfpDAl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorboard==1.13.0\n",
        "%reload_ext tensorboard.notebook \n",
        "%tensorboard --logdir 'gs://kmo-us-central1-misc/taxifare/feateng2.2m'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sH5LW7XqoUH7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Compare it to the following visualization of the model trained on 10x as much data. Notice that evaluation RMSE is roughly the same. This means that the model designed for the problem is no longer benefiting from the additional data. Nonetheless, **these models achieved and exceeded the original goal of RMSE of $6 or less!**"
      ]
    },
    {
      "metadata": {
        "id": "sz8JsfyJ2rTn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir 'gs://kmo-us-central1-misc/taxifare/feateng22m'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "noMWBnHu2rTr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Conclusions"
      ]
    },
    {
      "metadata": {
        "id": "cZCfh0Ya2rTt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The RMSE after training on the 2-million-row dataset is **$4.1**.  This graph shows the improvements you have achieved in this session."
      ]
    },
    {
      "metadata": {
        "id": "qlYAGYjd2rTu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = pd.DataFrame({'Method' : pd.Series(['Heuristic Benchmark', 'tf.learn', '+Feature Eng.', '+ Hyperparam', '+ 2m rows']),\n",
        "              'RMSE': pd.Series([8.026, 9.4, 8.3, 5.7, 4.1]) })\n",
        "\n",
        "ax = sns.barplot(data = df, x = 'Method', y = 'RMSE')\n",
        "ax.set_ylabel('RMSE (dollars)')\n",
        "ax.set_xlabel('Methods')\n",
        "plt.plot(np.linspace(-20, 120, 1000), [5] * 1000, 'b');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bQCzitOC2rT2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Copyright 2019 Counter Factual .AI LLC. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
      ]
    }
  ]
}